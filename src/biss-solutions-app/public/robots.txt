# Robots.txt para Biss Solutions
# https://biss.com.br/robots.txt

# User-agent: *
User-agent: *
Allow: /

# Permitir acesso a recursos importantes
Allow: /images/
Allow: /assets/
Allow: /favicon.ico
Allow: /sitemap.xml

# Bloquear acesso a arquivos sensíveis
Disallow: /admin/
Disallow: /api/
Disallow: /private/
Disallow: /temp/
Disallow: /logs/
Disallow: /config/
Disallow: /node_modules/
Disallow: /src/
Disallow: /dist/
Disallow: /.git/
Disallow: /.env
Disallow: /package.json
Disallow: /package-lock.json

# Bloquear arquivos específicos
Disallow: /*.json$
Disallow: /*.xml$
Disallow: /*.txt$
Disallow: /*.log$
Disallow: /*.sql$
Disallow: /*.bak$
Disallow: /*.tmp$

# Sitemap
Sitemap: https://biss.com.br/sitemap.xml

# Crawl-delay (opcional - para ser respeitoso com o servidor)
Crawl-delay: 1

# Regras específicas para Googlebot
User-agent: Googlebot
Allow: /
Crawl-delay: 1

# Regras específicas para Bingbot
User-agent: Bingbot
Allow: /
Crawl-delay: 1

# Regras específicas para Slurp (Yahoo)
User-agent: Slurp
Allow: /
Crawl-delay: 2

# Regras específicas para DuckDuckBot
User-agent: DuckDuckBot
Allow: /
Crawl-delay: 1

# Regras específicas para Facebook
User-agent: facebookexternalhit
Allow: /
Crawl-delay: 1

# Regras específicas para LinkedIn
User-agent: LinkedInBot
Allow: /
Crawl-delay: 1

# Regras específicas para Twitter
User-agent: Twitterbot
Allow: /
Crawl-delay: 1

# Regras específicas para WhatsApp
User-agent: WhatsApp
Allow: /
Crawl-delay: 1

# Regras específicas para Telegram
User-agent: TelegramBot
Allow: /
Crawl-delay: 1
